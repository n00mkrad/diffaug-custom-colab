{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmkd-diffaug.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eeNSzIXlB5QP"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZb8pDhKRxcS"
      },
      "source": [
        "# Data-Efficient GANs with DiffAugment\n",
        "\n",
        "In this tutorial, we will demonstrate \n",
        "- How to visualize and evaluate the pretrained models for 100-shot generation; and\n",
        "- How to train a new network with only 100 images.\n",
        "\n",
        "**[Differentiable Augmentation (DiffAugment)](https://github.com/mit-han-lab/data-efficient-gans)** is a simple, general method that enables **[Data-Efficient GAN Training](https://github.com/mit-han-lab/data-efficient-gans)** by imposing various types of differentiable augmentations on both real and fake samples for both generator and discriminator training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hstr-DtWUcVo",
        "cellView": "form"
      },
      "source": [
        "#@title Check GPU\n",
        "#@markdown P100/V100 recommended for StyleGAN2 training!\n",
        "\n",
        "gpu = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
        "print(\"GPU: \" + gpu[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4MvOMh1BNef"
      },
      "source": [
        "## Setup Environment\n",
        "\n",
        "1. Clone our repo:\n",
        "2. Go to the DiffAugment-stylegan2 folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqqY49pVYDqg"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/n00mkrad/data-efficient-gans\n",
        "%cd data-efficient-gans/DiffAugment-stylegan2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCTzjs2pYSKF"
      },
      "source": [
        "3. Prepare the preliminaries and define some functions for later uses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re5R6VX8VNgo"
      },
      "source": [
        "!pip uninstall -y tensorflow tensorflow-probability\n",
        "!pip install tensorflow-gpu==1.15.0\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL\n",
        "import IPython\n",
        "from multiprocessing import Pool\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dnnlib import tflib, EasyDict\n",
        "from training import misc, dataset_tool\n",
        "from metrics import metric_base\n",
        "from metrics.metric_defaults import metric_defaults\n",
        "\n",
        "def _generate(network_name, num_rows, num_cols, seed, resolution):\n",
        "  if seed is not None:\n",
        "    np.random.seed(seed)\n",
        "  with tf.Session():\n",
        "    _, _, Gs = misc.load_pkl(network_name)\n",
        "    z = np.random.randn(num_rows * num_cols, Gs.input_shape[1])\n",
        "    outputs = Gs.run(z, None, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
        "    outputs = np.reshape(outputs, [num_rows, num_cols, *outputs.shape[1:]])\n",
        "    outputs = np.concatenate(outputs, axis=1)\n",
        "    outputs = np.concatenate(outputs, axis=1)\n",
        "    img = PIL.Image.fromarray(outputs)\n",
        "    img = img.resize((resolution * num_cols, resolution * num_rows), PIL.Image.ANTIALIAS)\n",
        "  return img\n",
        "\n",
        "def generate(network_name, num_rows, num_cols, seed=None, resolution=128):\n",
        "  with Pool(1) as pool:\n",
        "    return pool.apply(_generate, (network_name, num_rows, num_cols, seed, resolution))\n",
        "\n",
        "def _evaluate(network_name, dataset, resolution, metric):\n",
        "  dataset = dataset_tool.create_dataset(dataset, resolution)\n",
        "  dataset_args = EasyDict(tfrecord_dir=dataset, resolution=resolution, from_tfrecords=True)\n",
        "  metric_group = metric_base.MetricGroup([metric_defaults[metric]])\n",
        "  metric_group.run(network_name, dataset_args=dataset_args, log_results=False)\n",
        "  return metric_group.metrics[0]._results[0].value\n",
        "\n",
        "def evaluate(network_name, dataset, resolution=256, metric='fid5k-train'):\n",
        "  with Pool(1) as pool:\n",
        "    return pool.apply(_evaluate, (network_name, dataset, resolution, metric))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeNSzIXlB5QP"
      },
      "source": [
        "## Using the Pre-Trained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APrapkROPF38"
      },
      "source": [
        "### 100-Shot Generation Datasets\n",
        "\n",
        "Let's first visualize the 100-shot Obama dataset. Such a small-scale dataset can be easily collected from the Internet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaQzEznPWYt"
      },
      "source": [
        "data_dir = dataset_tool.create_dataset('100-shot-obama')\n",
        "training_images = []\n",
        "for fname in os.listdir(data_dir):\n",
        "  if fname.endswith('.jpg'):\n",
        "    training_images.append(np.array(PIL.Image.open(os.path.join(data_dir, fname))))\n",
        "imgs = np.reshape(training_images, [5, 20, *training_images[0].shape])\n",
        "imgs = np.concatenate(imgs, axis=1)\n",
        "imgs = np.concatenate(imgs, axis=1)\n",
        "PIL.Image.fromarray(imgs).resize((1000, 250), PIL.Image.ANTIALIAS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ise7tDly52n"
      },
      "source": [
        "### StyleGAN2 (baseline)\n",
        "\n",
        "How do vanilla GANs perform given such a small dataset? Let's visualize the (pre-trained) StyleGAN2 baseline model (this will take a minute):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFPQahiKu0nD"
      },
      "source": [
        "generate('mit-han-lab:stylegan2-100-shot-obama.pkl', num_rows=2, num_cols=5, seed=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PM1dI0LT_U-"
      },
      "source": [
        "As you can see, most of the images generated by the baseline model are heavily distorted. This is mainly because the discriminator is memorizing the exact training images. Let's resolve this problem with DiffAugment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHC5M0yH767k"
      },
      "source": [
        "###  + DiffAugment (ours)\n",
        "\n",
        "DiffAugment can dramatically improve the image quality even with only 100 training images of Obama portraits. Here visualizes the (pre-trained) StyleGAN2 + DiffAugment model (this will take a minute):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjwREhZK71EN"
      },
      "source": [
        "generate('mit-han-lab:DiffAugment-stylegan2-100-shot-obama.pkl', num_rows=2, num_cols=5, seed=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VKNmZl8Hg6"
      },
      "source": [
        "Besides `100-shot-obama`, you may also try out `100-shot-grumpy_cat`, `100-shot-panda`, `AnimalFace-cat`, or `AnimalFace-dog` in the code above, to compare DiffAugment with the baseline models on other datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbbGjezUWtqC"
      },
      "source": [
        "### Calculating FID\n",
        "\n",
        "FrÃ©chet Inception Distance (FID) quatitatively measures the visual fidelity for GANs. Lower FID indicates better performance. Let's do the FID calculation for both the baseline model and ours. This will take about 15 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLYCnN36W73k"
      },
      "source": [
        "print('Evaluating StyleGAN2 (baseline)...')\n",
        "fid_baseline = evaluate('mit-han-lab:stylegan2-100-shot-obama.pkl', dataset='100-shot-obama')\n",
        "print('Baseline FID:', fid_baseline, '\\n')\n",
        "\n",
        "print('Evaluating StyleGAN2 + DiffAugment (ours)...')\n",
        "fid_ours = evaluate('mit-han-lab:DiffAugment-stylegan2-100-shot-obama.pkl', dataset='100-shot-obama')\n",
        "print('Ours FID:', fid_ours, '\\n')\n",
        "\n",
        "plt.figure(figsize=(2, 3))\n",
        "plt.bar([0, 1], [fid_baseline, fid_ours], color=['gray', 'darkred'])\n",
        "plt.xticks([0, 1], ['Baseline', 'Ours'])\n",
        "plt.ylabel(\"FID\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e4dITWJjQGO"
      },
      "source": [
        "With DiffAugment, our model is **1.7x** better than the baseline model in terms of FID!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm4ESGLC5Tpr"
      },
      "source": [
        "### Generating an Interpolation Video\n",
        "\n",
        "Finally, let's generate an interpolation video using the pre-trained DiffAugment models. Besides `obama`, you may also try out `grumpy_cat`, `panda`, `bridge_of_sighs`, `medici_fountain`, `temple_of_heaven` in the code below. The smooth interpolation results suggest little overfitting of our method even given small datasets. This will take a minute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Q7bwdKvws9"
      },
      "source": [
        "!python3 generate_gif.py -r mit-han-lab:DiffAugment-stylegan2-100-shot-obama.pkl -o interp.gif --num-rows=2 --num-cols=3 --seed=1\n",
        "IPython.display.Image(open('interp.gif', 'rb').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZR5jladNYlI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPBpxIl3gmCG",
        "cellView": "form"
      },
      "source": [
        "#@title Mount Google Drive at /content/drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nb-8coliB-a"
      },
      "source": [
        "!cp \"YOUR_GOOGLE_DRIVE_DATASET_ZIP_PATH_HERE\" \"/content/data-efficient-gans/DiffAugment-stylegan2/datasets/dataset1.zip\"\n",
        "!unzip -q \"/content/data-efficient-gans/DiffAugment-stylegan2/datasets/dataset1.zip\" -d \"/content/data-efficient-gans/DiffAugment-stylegan2/datasets/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdkCbnHvuNuc"
      },
      "source": [
        "Start training with this cell.\n",
        "\n",
        "Add this if you want to resume:\n",
        "\n",
        "`--resume \"PATH_TO_YOUR_LATEST_CHECKPOINT.pkl\" --resume-kimg KIMG_NUMBER_HERE`\n",
        "\n",
        "Replace the path with your latest checkpoint file and replace `KIMG_NUMBER_HERE` with that model's kimg count.\n",
        "This is optional, but if you don't do this, you will lose track of the actual amount as it's not stored within the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywR-TqhzY01I"
      },
      "source": [
        "# Train the model at 256px\n",
        "!python3 run_few_shot.py --dataset=\"/content/data-efficient-gans/DiffAugment-stylegan2/datasets/YOUR_DATASET_FOLDER_NAME\" --resolution=256 --batch-size 4 --result-dir \"YOUR_GOOGLE_DRIVE_CHECKPOINT_PATH\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}